"""
Basic Sentiment Analysis Example for Thai Text
A simple implementation of binary sentiment classification using WangchanBERTa.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import sys
import os

# Add parent directory to path to import our pipeline
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.text_classification_pipeline import TextClassificationPipeline

def create_thai_sentiment_data():
    """Create a larger sample dataset for Thai sentiment analysis."""
    
    positive_samples = [
        "‡∏ú‡∏°‡∏ä‡∏≠‡∏ö‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å ‡∏™‡∏ô‡∏∏‡∏Å‡πÅ‡∏•‡∏∞‡∏ô‡πà‡∏≤‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô",
        "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏û‡∏á ‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤‡πÄ‡∏á‡∏¥‡∏ô ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏•‡∏¢", 
        "‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°‡∏ô‡∏µ‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏™‡∏ö‡∏≤‡∏¢ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡∏µ ‡∏ß‡∏¥‡∏ß‡∏™‡∏ß‡∏¢",
        "‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å ‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏î‡∏µ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å ‡∏à‡∏∞‡∏°‡∏≤‡∏≠‡∏µ‡∏Å",
        "‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏™‡πà‡πÉ‡∏à‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡∏û‡∏≠‡πÉ‡∏à‡∏°‡∏≤‡∏Å",
        "‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° ‡∏™‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ ‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à‡∏°‡∏≤‡∏Å",
        "‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏Å ‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å",
        "‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡∏à‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô",
        "‡∏ô‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏Å ‡∏î‡∏µ‡πÑ‡∏ã‡∏ô‡πå‡∏™‡∏ß‡∏¢ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°",
        "‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à‡∏°‡∏≤‡∏Å ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏µ‡∏Å",
        "‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥‡∏î‡∏µ ‡∏´‡∏≠‡∏° ‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°",
        "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î",
        "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß",
        "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô ‡∏™‡∏á‡∏ö",
        "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"
    ]
    
    negative_samples = [
        "‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏î‡∏µ",
        "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏°‡∏≤‡∏≠‡∏µ‡∏Å",
        "‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏•‡πà‡∏°‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡πÄ‡∏ö‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏Å ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥",
        "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥ ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏á‡∏¥‡∏ô",
        "‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤ ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏°‡∏≤‡∏Å",
        "‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏•‡∏¢ ‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡πÑ‡∏°‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤‡πÄ‡∏á‡∏¥‡∏ô ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ã‡∏∑‡πâ‡∏≠‡∏≠‡∏µ‡∏Å",
        "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ã‡∏∑‡πâ‡∏≠ ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏õ‡∏•‡πà‡∏≤",
        "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡πà",
        "‡πÑ‡∏°‡πà‡∏î‡∏µ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥ ‡πÑ‡∏°‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤ ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ã‡∏∑‡πâ‡∏≠‡∏≠‡∏µ‡∏Å",
        "‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤",
        "‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏¢‡πà ‡πÑ‡∏°‡πà‡∏™‡∏î ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏á‡∏¥‡∏ô",
        "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏´‡∏¢‡∏≤‡∏ö‡∏Ñ‡∏≤‡∏¢ ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏î‡∏µ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏°‡∏≤‡∏£‡∏¢‡∏≤‡∏ó",
        "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤ ‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à",
        "‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á ‡∏£‡∏ö‡∏Å‡∏ß‡∏ô ‡πÑ‡∏°‡πà‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏™‡∏ö‡∏≤‡∏¢",
        "‡πÄ‡∏Å‡πà‡∏≤ ‡∏ä‡πâ‡∏≤ ‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏¢‡∏≤‡∏Å"
    ]
    
    # Create DataFrame
    data = {
        'text': positive_samples + negative_samples,
        'label': ['positive'] * len(positive_samples) + ['negative'] * len(negative_samples)
    }
    
    return pd.DataFrame(data)

def main():
    """Main function to run sentiment analysis example."""
    
    print("üöÄ Thai Sentiment Analysis Example")
    print("=" * 50)
    
    # Create dataset
    print("üìä Creating sample dataset...")
    df = create_thai_sentiment_data()
    
    print(f"   Total samples: {len(df)}")
    print(f"   Positive samples: {len(df[df['label'] == 'positive'])}")
    print(f"   Negative samples: {len(df[df['label'] == 'negative'])}")
    
    # Initialize pipeline
    print("\nü§ñ Initializing text classification pipeline...")
    pipeline = TextClassificationPipeline(
        model_name="airesearch/wangchanberta-base-att-spm-uncased",
        num_labels=2,
        max_length=256  # Shorter length for this example
    )
    
    # Load model and tokenizer
    pipeline.load_model_and_tokenizer()
    
    # Prepare dataset
    print("\nüìã Preparing dataset...")
    dataset_dict = pipeline.prepare_dataset(
        df,
        text_column='text',
        label_column='label',
        test_size=0.3,
        val_size=0.2
    )
    
    print(f"   Label mappings: {pipeline.label2id}")
    
    # Configure training (reduced parameters for quick demo)
    training_config = {
        'learning_rate': 2e-5,
        'batch_size': 8,
        'num_epochs': 2,  # Reduced for quick demo
        'warmup_steps': 50,
        'weight_decay': 0.01,
        'eval_steps': 10,
        'logging_steps': 5,
        'save_steps': 50,
        'early_stopping_patience': 2,
        'output_dir': './sentiment_model_results'
    }
    
    # Fine-tune model
    print("\nüéØ Starting fine-tuning...")
    results = pipeline.fine_tune(dataset_dict, **training_config)
    
    print(f"\n‚úÖ Training completed!")
    print(f"   Final test results: {results['test_results']}")
    
    # Test inference
    print("\nüîç Testing inference...")
    
    test_sentences = [
        "‡∏£‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°",  # Should be positive
        "‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à‡πÄ‡∏•‡∏¢ ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÅ‡∏¢‡πà ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏î‡∏µ",             # Should be negative  
        "‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏ô‡∏∞ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ ‡∏õ‡∏Å‡∏ï‡∏¥",                          # Neutral/positive
        "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å‡πÜ ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏á‡∏¥‡∏ô"                    # Should be negative
    ]
    
    for i, sentence in enumerate(test_sentences, 1):
        prediction = pipeline.predict(sentence)
        probabilities = pipeline.predict(sentence, return_probabilities=True)
        
        print(f"\n{i}. Text: {sentence}")
        print(f"   Prediction: {prediction}")
        print(f"   Probabilities: {dict(zip(pipeline.id2label.values(), probabilities.round(4)))}")
    
    # Evaluate model comprehensively
    print("\nüìä Comprehensive evaluation...")
    evaluation_results = pipeline.evaluate_model(dataset_dict, plot_confusion_matrix=True)
    
    print("\nüéâ Sentiment analysis example completed!")
    print(f"üíæ Model saved in: {training_config['output_dir']}")
    
    return pipeline, results

if __name__ == "__main__":
    pipeline, results = main()
